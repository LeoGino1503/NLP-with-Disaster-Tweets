{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"17JUXMEPjV9_ypxiopgz4BAdyDwxKvu_U","authorship_tag":"ABX9TyOH9HJmhfhbmopCiHaDNdK2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"8SMe96vVhfTN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","df = pd.read_csv('/content/drive/MyDrive/NLP with Disaster Tweets/train.csv')\n","\n","df.head()"],"metadata":{"id":"PqlKhT3oiLve"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.info()"],"metadata":{"id":"Bwt_ykJmivr9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_disaster = df[df['target'] == 1]\n","df_disaster"],"metadata":{"id":"rt_Q3QT4jBds"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["m,n = df.shape\n","rate = 0.8\n","X_train = df.iloc[:round(rate*m),-2]\n","y_train = df.iloc[:round(rate*m),-1].values\n","X_train.head(), y_train"],"metadata":{"id":"yDWpliz84Z6j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_val = df.iloc[round(rate*m):,-2]\n","y_val = df.iloc[round(rate*m):,-1].values\n","X_val.head(), y_val[:5]"],"metadata":{"id":"1eqTfQvR5ZLD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.feature_extraction.text import CountVectorizer\n","\n","vect = CountVectorizer()\n","vocabulary = vect.fit_transform(X_train)\n","words = vect.get_feature_names()\n","len(words)"],"metadata":{"id":"UinBobmQOS9S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import nltk\n","nltk.download('words')\n","nltk.download('stopwords')"],"metadata":{"id":"v0yAADTFl3h4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Loại bỏ các stopwords\n","import nltk\n","from nltk.corpus import stopwords\n","\n","stops = list(stopwords.words('english'))\n","for i in range(0,len(stops)):\n","  if stops[i] in words:\n","    words.remove(stops[i])\n","\n","len(words)"],"metadata":{"id":"M1s4dzZPL1pS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Loại bỏ các từ vô nghĩa\n","meaningful = list(nltk.corpus.words.words())\n","j = 0\n","while j < len(words):\n","  if words[j] not in meaningful:\n","    words.remove(words[j])\n","  else:\n","    j += 1\n","len(words)"],"metadata":{"id":"w9xnVw9AknbI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["words[:5]"],"metadata":{"id":"Na8tgTGhpm_P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# test voi X_train[0]\n","X_train[0]"],"metadata":{"id":"2i8K75XUswfz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import re\n","l_doc = re.sub(r\"[^a-zA-Z0-9]\", \" \", X_train[0].lower()).split()\n","l_doc"],"metadata":{"id":"anw3puKEuvd9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","def bag_of_word(sentence):\n","  vector = np.zeros(len(words))\n","  for n in range(0,len(words)):\n","    count = 0\n","    for word in sentence:\n","      if words[n]== word:\n","        count = count + 1\n","        # print(word, count)\n","    vector[n] = count \n","  return vector\n","\n","bag_of_word(l_doc)\n","# print('vector: ', bag_of_word(l_doc)[1500:2000])"],"metadata":{"id":"DD6WW1E13Lrt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import re\n","\n","i = 0\n","X_vector = []\n","for i in range(0,len(X_train)):\n","  l_doc = re.sub(r\"[^a-zA-Z0-9]\", \" \", X_train[i].lower()).split()\n","  vector = bag_of_word(l_doc)\n","  X_vector.append(vector)\n","\n","X_vector"],"metadata":{"id":"17Lc6QcwT9sL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(X_vector)"],"metadata":{"id":"zOn10sv-cBY3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn import svm\n","classifier = svm.SVC(C=10,kernel=\"rbf\")\n","classifier.fit(X_vector,y_train)\n"],"metadata":{"id":"yY2Pp44cdC6b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["i = 0\n","X_vector_test = []\n","for i in range(round(rate*m),len(df)):\n","  l_doc = re.sub(r\"[^a-zA-Z0-9]\", \" \", X_val[i].lower()).split()\n","  vector = bag_of_word(l_doc)\n","  X_vector_test.append(vector)\n","\n","len(X_vector_test)"],"metadata":{"id":"22RY0KBFdi5A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_predict = classifier.predict(X_vector_test)\n","\n","from sklearn import metrics\n","\n","print(\"Accuracy:\",metrics.accuracy_score(y_val, y_predict))\n","print(\"Precision:\",metrics.precision_score(y_val, y_predict))\n","print(\"Recall:\",metrics.recall_score(y_val, y_predict))\n","print(\"F1_Score:\",metrics.f1_score(y_val, y_predict))"],"metadata":{"id":"x1ZS9jWJdjAE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Cải thiện mô hình bằng phương pháp PCA**"],"metadata":{"id":"Kc3qIcJHpiTi"}},{"cell_type":"code","source":["# Improve with PCA\n","from sklearn.decomposition import PCA\n","\n","pca = PCA(0.9)\n","X_vector_PCA = pca.fit_transform(X_vector)\n","\n","n_components = pca.n_components_\n","\n","PCA_test = PCA(n_components)\n","\n","n_components, PCA_test, pca"],"metadata":{"id":"kOOyY_Vnh2I-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_vector_PCA.shape"],"metadata":{"id":"B8315di3NqMC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn import svm\n","classifier = svm.SVC(C=10,kernel=\"rbf\")\n","classifier.fit(X_vector_PCA,y_train)\n","i = 0\n","X_vector_test = []\n","for i in range(round(rate*m),len(df)):\n","  l_doc = re.sub(r\"[^a-zA-Z0-9]\", \" \", X_val[i].lower()).split()\n","  vector = bag_of_word(l_doc)\n","  X_vector_test.append(vector)"],"metadata":{"id":"GXryOX8MQxtC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["PCA_test = PCA(n_components)\n","X_vector_test = np.array(X_vector_test)\n","X_test_PCA = PCA_test.fit_transform(X_vector_test)\n","X_test_PCA.shape, y_val.shape"],"metadata":{"id":"SQxC0k3YcSwR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_predict = classifier.predict(X_test_PCA)\n","\n","from sklearn import metrics\n","\n","print(\"Accuracy:\",metrics.accuracy_score(y_val, y_predict))\n","print(\"Precision:\",metrics.precision_score(y_val, y_predict))\n","print(\"Recall:\",metrics.recall_score(y_val, y_predict))\n","print(\"F1_Score:\",metrics.f1_score(y_val, y_predict))"],"metadata":{"id":"3dVvEoxEmJNq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ta nhận thấy kết quả thu được không như mong đợi vì:\n","1.   Với số chiều là 761 là quá nhỏ, phần thông tin bị lượt bỏ quá nhiều so với khoảng 950 chiều tương đương 90% thông tin.\n","2.   Hạn chế trong phương thức PCA gặp lỗi nếu số chiều feature chỉ có thể nằm trong khoảng 0 đến min(sample). Nghe hơi vô lí nhưng tôi cần xem xét lại. Để giải quyết vấn đề này chúng ta cần số mẫu thử (test) lớn hơn. Hy vọng có thể cải thiện được mô hình \n","\n"],"metadata":{"id":"Qn3AxANUpuUa"}}]}